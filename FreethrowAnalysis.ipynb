{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "M7PIw8IhEljY"
      },
      "outputs": [],
      "source": [
        "# Pytorch version Compatible with mmcv prebuilt wheels\n",
        "!pip install -q torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Transformers version to match\n",
        "\n",
        "!pip install -q transformers==4.30.2\n",
        "\n",
        "# Fast MMPose Setup for Colab Pro (no manual wheel building)\n",
        "!pip install -q -U openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmdet==3.0.0\"\n",
        "!mim install \"mmcv==2.0.0\"  # No wheel build ‚Äî fast precompiled binary\n",
        "\n",
        "# Ultralytics install\n",
        "!pip install ultralytics\n",
        "\n",
        "# Downgrade to stable NumPy\n",
        "\n",
        "!pip install numpy==1.26.4\n",
        "\n",
        "# Gradio install for gui through Colab\n",
        "!pip install gradio\n",
        "\n",
        "#install dynamic time warping function for analysis phase\n",
        "!pip install dtw\n",
        "\n",
        "# stable matplotlib version that works with mmpose functions\n",
        "\n",
        "!pip install --upgrade matplotlib==3.5.2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z34dwgusiXrr"
      },
      "outputs": [],
      "source": [
        "# Must restart colab session for package versions to update\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "k6IASYnXTts_"
      },
      "outputs": [],
      "source": [
        "# MMPose install\n",
        "!git clone https://github.com/open-mmlab/mmpose.git\n",
        "%cd mmpose\n",
        "!pip install -v -e .  # Editable install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjvag2ycZxMi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from mmpose.apis import visualize, MMPoseInferencer\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import transformers\n",
        "import mmcv\n",
        "import mmdet\n",
        "import mmengine\n",
        "import mmpose\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from dtw import dtw\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import shutil\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siidlEMLutSP"
      },
      "outputs": [],
      "source": [
        "def lock_shooter(video_path, yolo_model, mmpose_inferencer, ball_class_id=0, conf_thresh=0.6, scan_frames=100):\n",
        "    \"\"\"\n",
        "    Lock onto the shooter and return only the visualisation (without side-by-side original image).\n",
        "    Falls back to using the only detected person if no ball is found.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frame_id = 0\n",
        "\n",
        "    while frame_id < scan_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_id += 1\n",
        "        print(f\"üîç Scanning frame {frame_id}\")\n",
        "\n",
        "        # Convert frame to RGB\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_copy = frame_rgb.copy()\n",
        "\n",
        "        # YOLOv11 ball detection\n",
        "        results = yolo_model(frame)[0]\n",
        "        boxes = results.boxes\n",
        "\n",
        "        ball_boxes = [\n",
        "            boxes[i] for i in range(len(boxes))\n",
        "            if boxes.conf[i] > conf_thresh and int(boxes.cls[i]) == ball_class_id\n",
        "        ]\n",
        "\n",
        "        # MMPose detection\n",
        "        pose_result = next(mmpose_inferencer(frame_rgb, return_vis=False))\n",
        "        pred_instances = pose_result['predictions'][0]\n",
        "        if not pred_instances:\n",
        "            continue  # no people found\n",
        "\n",
        "        # PRIMARY: Use ball if found\n",
        "        if ball_boxes:\n",
        "            ball_box = ball_boxes[0]\n",
        "            x1, y1, x2, y2 = ball_box.xyxy[0].tolist()\n",
        "            ball_center = np.array([(x1 + x2) / 2, (y1 + y2) / 2])\n",
        "\n",
        "            min_dist = float('inf')\n",
        "            shooter_idx = None\n",
        "            shooter_bbox = None\n",
        "\n",
        "            for idx, person in enumerate(pred_instances):\n",
        "                keypoints = person['keypoints']\n",
        "                left_wrist = keypoints[9][:2]\n",
        "                right_wrist = keypoints[10][:2]\n",
        "\n",
        "                dist_left = np.linalg.norm(left_wrist - ball_center)\n",
        "                dist_right = np.linalg.norm(right_wrist - ball_center)\n",
        "                min_person_dist = min(dist_left, dist_right)\n",
        "\n",
        "                if min_person_dist < min_dist:\n",
        "                    min_dist = min_person_dist\n",
        "                    shooter_idx = idx\n",
        "                    shooter_bbox = person['bbox'][0]\n",
        "\n",
        "            if shooter_bbox:\n",
        "                print(f\"‚úÖ Shooter locked at frame {frame_id} (via ball)\")\n",
        "                cap.release()\n",
        "                return frame_id, shooter_bbox\n",
        "\n",
        "        # FALLBACK: Only one person -> assume shooter\n",
        "        elif len(pred_instances) == 1:\n",
        "            shooter_data = pred_instances[0]\n",
        "            shooter_bbox = shooter_data['bbox'][0]\n",
        "            print(f\"‚úÖ Shooter locked at frame {frame_id} (fallback: only one person)\")\n",
        "            cap.release()\n",
        "            return frame_id, shooter_bbox\n",
        "\n",
        "    cap.release()\n",
        "    print(\"‚ùå Could not lock shooter in first N frames.\")\n",
        "    return (None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoUQIluVBFOw"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    # Calculates overlappng bounding box area for tracking\n",
        "    x1_inter = max(box1[0], box2[0])\n",
        "    y1_inter = max(box1[1], box2[1])\n",
        "    x2_inter = min(box1[2], box2[2])\n",
        "    y2_inter = min(box1[3], box2[3])\n",
        "\n",
        "    width_inter = max(0, x2_inter - x1_inter)\n",
        "    height_inter = max(0, y2_inter - y1_inter)\n",
        "    area_inter = width_inter * height_inter\n",
        "\n",
        "    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    area_union = area_box1 + area_box2 - area_inter\n",
        "\n",
        "    return area_inter / area_union if area_union > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GoYA4vAFpUL"
      },
      "outputs": [],
      "source": [
        "def track_shooter_full_video(video_path, yolo_model, mmpose_inferencer, ball_class_id=0, conf_thresh=0.6, scan_frames=100):\n",
        "    \"\"\"\n",
        "    Track the shooter through the entire video and collect keypoint data.\n",
        "\n",
        "    Args:\n",
        "        video_path: Path to the input video file\n",
        "        yolo_model: Loaded YOLO model\n",
        "        mmpose_inferencer: Loaded MMPose inferencer\n",
        "        ball_class_id: Class ID for basketball in YOLO\n",
        "        conf_thresh: Confidence threshold for detections\n",
        "        scan_frames: Number of frames to scan initially to find shooter\n",
        "\n",
        "    Returns:\n",
        "        shooter_keypoints_data: Dictionary with:\n",
        "        {\n",
        "            frame_num: {\n",
        "                'bbox': [x1, y1, x2, y2],\n",
        "                'keypoints': np.array of shape (N, 3)  # (x, y, score)\n",
        "                'keypoint_scores': np.array of shape (N,)\n",
        "                'ball_bbox': [x1, y1, x2, y2] or None\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Could not open video {video_path}\")\n",
        "\n",
        "    # Get video properties\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Find initial shooter\n",
        "    print(\"üîç Finding initial shooter...\")\n",
        "    start_frame, shooter_bbox = lock_shooter(\n",
        "        video_path, yolo_model, mmpose_inferencer,\n",
        "        ball_class_id, conf_thresh, scan_frames,\n",
        "    )\n",
        "\n",
        "    if start_frame is None:\n",
        "        cap.release()\n",
        "        raise RuntimeError(\"Could not find shooter in initial frames\")\n",
        "\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "    frame_num = start_frame\n",
        "\n",
        "    # Data storage\n",
        "    shooter_keypoints_data = {}\n",
        "    pbar = tqdm(total=total_frames - start_frame, desc=\"Tracking shooter\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame_data = {\n",
        "            'bbox': None,\n",
        "            'keypoints': None,\n",
        "            'keypoint_scores': None,\n",
        "            'ball_bbox': None\n",
        "        }\n",
        "\n",
        "        # 1. YOLO ball detection\n",
        "        results = yolo_model(frame)[0]\n",
        "        boxes = results.boxes\n",
        "        ball_boxes = [\n",
        "            boxes[i] for i in range(len(boxes))\n",
        "            if boxes.conf[i] > conf_thresh and int(boxes.cls[i]) == ball_class_id\n",
        "        ]\n",
        "\n",
        "        if ball_boxes:\n",
        "            ball_box = ball_boxes[0]\n",
        "            frame_data['ball_bbox'] = ball_box.xyxy[0].tolist()\n",
        "\n",
        "        # 2. MMPose detection\n",
        "        pose_result = next(mmpose_inferencer(frame_rgb, return_vis=False))\n",
        "        pred_instances = pose_result['predictions'][0]\n",
        "\n",
        "        if pred_instances:\n",
        "            # Find person with highest IoU with previous shooter bbox\n",
        "            max_iou = 0\n",
        "            current_shooter_bbox = None\n",
        "            shooter_idx = None\n",
        "\n",
        "            for idx, person in enumerate(pred_instances):\n",
        "                current_bbox = person['bbox'][0]\n",
        "                iou = calculate_iou(shooter_bbox, current_bbox)\n",
        "\n",
        "                if iou > max_iou:\n",
        "                    max_iou = iou\n",
        "                    current_shooter_bbox = current_bbox\n",
        "                    shooter_idx = idx\n",
        "\n",
        "            # Update tracking if good match found\n",
        "            if current_shooter_bbox is not None and max_iou >= 0.1:\n",
        "                shooter_bbox = current_shooter_bbox\n",
        "                frame_data['bbox'] = shooter_bbox\n",
        "                frame_data['keypoints'] = np.array(pred_instances[shooter_idx]['keypoints'])\n",
        "                frame_data['keypoint_scores'] = np.array(pred_instances[shooter_idx].get('keypoint_scores', []))\n",
        "\n",
        "        shooter_keypoints_data[frame_num] = frame_data\n",
        "        frame_num += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "    cap.release()\n",
        "    print(\"‚úÖ Tracking complete.\")\n",
        "    return shooter_keypoints_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4S5vby_20nH"
      },
      "outputs": [],
      "source": [
        "def calculate_knee_angle(keypoints, hip_idx=11, knee_idx=13, ankle_idx=15):\n",
        "    \"\"\"Calculates knee angle (hip-knee-ankle) in degrees\"\"\"\n",
        "    hip = keypoints[hip_idx][:2]\n",
        "    knee = keypoints[knee_idx][:2]\n",
        "    ankle = keypoints[ankle_idx][:2]\n",
        "\n",
        "    # Vectors from knee to hip and ankle\n",
        "    vec_hk = np.array(hip) - np.array(knee)\n",
        "    vec_ak = np.array(ankle) - np.array(knee)\n",
        "\n",
        "    # Calculate angle\n",
        "    cosine = np.dot(vec_hk, vec_ak) / (np.linalg.norm(vec_hk) * np.linalg.norm(vec_ak))\n",
        "    angle = np.degrees(np.arccos(np.clip(cosine, -1, 1)))\n",
        "    return angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjp6uuLR1mtP"
      },
      "outputs": [],
      "source": [
        "def find_load_frame(frames_dict, release_frame, y_tolerance=5 , lefty=False):\n",
        "    \"\"\"\n",
        "    Finds load frame by working backwards from release until elbow crosses shoulder.\n",
        "\n",
        "    y_tolerance: Allowed pixels elbow can be below shoulder\n",
        "\n",
        "    Returns:\n",
        "        int: Frame number of load position or None\n",
        "    \"\"\"\n",
        "    # Switching joints for left handed shooters\n",
        "    if lefty:\n",
        "        shoulder_idx, elbow_idx, wrist_idx = 5, 7, 9\n",
        "    else:\n",
        "        shoulder_idx, elbow_idx, wrist_idx = 6, 8, 10\n",
        "\n",
        "    load_frame = None\n",
        "\n",
        "    # Work backwards from frame before release\n",
        "    for frame_num in range(release_frame-1, 0, -1):\n",
        "        if frame_num not in frames_dict:\n",
        "            continue\n",
        "\n",
        "        kps = frames_dict[frame_num]['keypoints']\n",
        "\n",
        "        # Get required joints (ensure they exist)\n",
        "        if any(idx >= len(kps) for idx in [shoulder_idx, elbow_idx]):\n",
        "            continue\n",
        "\n",
        "        shoulder_y = kps[shoulder_idx][1]\n",
        "        elbow_y = kps[elbow_idx][1]\n",
        "\n",
        "        # Check elbow is at/above shoulder (with tolerance)\n",
        "        if elbow_y <= shoulder_y + y_tolerance:\n",
        "            load_frame = frame_num\n",
        "            # Continue searching backwards in case we find earlier load\n",
        "        else:\n",
        "            # Stop when we exit the load phase\n",
        "            if load_frame is not None:\n",
        "                break\n",
        "    load_angle = calculate_elbow_angle(kps, shoulder_idx, elbow_idx, wrist_idx)\n",
        "    knee_angle = calculate_knee_angle(kps)\n",
        "    return load_frame , load_angle, knee_angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNQhcTMlRhgQ"
      },
      "outputs": [],
      "source": [
        "def find_preparation_frame(frames_dict, load_frame, still_frame_thresh=3, lefty=False):\n",
        "    \"\"\"\n",
        "    Detects the preparation start frame by tracking upward wrist motion.\n",
        "    Works backwards from the load frame until wrist hasn't moved upward\n",
        "    for a number of frames (indicating stillness before shot begins).\n",
        "\n",
        "\n",
        "    still_frame_thresh: How many frames of no upward wrist movement are required to count as 'stillness'\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        int: Frame number where preparation phase begins\n",
        "    \"\"\"\n",
        "\n",
        "    # Use dominant wrist based on handedness (COCO indices)\n",
        "    wrist_idx = 9 if lefty else 10\n",
        "    prep_frame = load_frame - 1\n",
        "    no_upward_motion = 0\n",
        "    prev_y = None\n",
        "\n",
        "    for frame_num in range(load_frame - 2, 0, -1):\n",
        "        if frame_num not in frames_dict:\n",
        "            continue\n",
        "\n",
        "        kps = frames_dict[frame_num]['keypoints']\n",
        "        if wrist_idx >= len(kps):\n",
        "            continue\n",
        "\n",
        "        wrist_y = kps[wrist_idx][1]\n",
        "\n",
        "        if prev_y is not None:\n",
        "            delta_y = prev_y - wrist_y  # Positive = upward\n",
        "            if delta_y > 0:\n",
        "                # Wrist is moving upward\n",
        "                no_upward_motion = 0\n",
        "            else:\n",
        "                # Wrist has stopped rising\n",
        "                no_upward_motion += 1\n",
        "\n",
        "        if no_upward_motion >= still_frame_thresh:\n",
        "            prep_frame = frame_num\n",
        "            break\n",
        "\n",
        "        prev_y = wrist_y\n",
        "\n",
        "    return prep_frame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ-l9iSt2zzM"
      },
      "outputs": [],
      "source": [
        "def calculate_elbow_angle(keypoints, shoulder_idx=12, elbow_idx=14, wrist_idx=16):\n",
        "    \"\"\"Calculates elbow angle (shoulder-elbow-wrist) in degrees\"\"\"\n",
        "\n",
        "    shoulder = keypoints[shoulder_idx][:2]\n",
        "    elbow = keypoints[elbow_idx][:2]\n",
        "    wrist = keypoints[wrist_idx][:2]\n",
        "\n",
        "    # Vectors from elbow to shoulder and wrist\n",
        "    vec_se = np.array(shoulder) - np.array(elbow)\n",
        "    vec_ew = np.array(wrist) - np.array(elbow)\n",
        "\n",
        "    # Calculate angle\n",
        "    cosine = np.dot(vec_se, vec_ew) / (np.linalg.norm(vec_se) * np.linalg.norm(vec_ew))\n",
        "    angle = np.degrees(np.arccos(np.clip(cosine, -1, 1)))\n",
        "    return angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgoFzqt8b2-8"
      },
      "outputs": [],
      "source": [
        "def generate_elbow_angle_sequence(frames_dict, prep_frame, release_frame, lefty=False):\n",
        "    \"\"\"\n",
        "    Extracts a sequence of elbow angles from prep to release using calculate_elbow_angle().\n",
        "\n",
        "    Returns:\n",
        "        List of elbow angles (float) per frame\n",
        "    \"\"\"\n",
        "    # COCO keypoint indices: shoulder, elbow, wrist\n",
        "    if lefty:\n",
        "        shoulder_idx, elbow_idx, wrist_idx = 5, 7, 9\n",
        "    else:\n",
        "        shoulder_idx, elbow_idx, wrist_idx = 6, 8, 10\n",
        "\n",
        "    angle_sequence = []\n",
        "\n",
        "    for frame_num in range(prep_frame, release_frame + 1):\n",
        "        if frame_num not in frames_dict:\n",
        "            continue\n",
        "\n",
        "        keypoints = frames_dict[frame_num]['keypoints']\n",
        "\n",
        "        if any(idx >= len(keypoints) for idx in [shoulder_idx, elbow_idx, wrist_idx]):\n",
        "            continue\n",
        "\n",
        "        angle = calculate_elbow_angle(\n",
        "            keypoints,\n",
        "            shoulder_idx=shoulder_idx,\n",
        "            elbow_idx=elbow_idx,\n",
        "            wrist_idx=wrist_idx\n",
        "        )\n",
        "\n",
        "        angle_sequence.append(angle)\n",
        "\n",
        "    return angle_sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Xx1ev4hcfE"
      },
      "outputs": [],
      "source": [
        "def generate_knee_angle_sequence(frames_dict, prep_frame, release_frame, lefty=False):\n",
        "    \"\"\"\n",
        "    Extracts a sequence of knee angles from prep to release.\n",
        "\n",
        "    Returns:\n",
        "        List of knee angles (float) per frame\n",
        "    \"\"\"\n",
        "    # COCO indices for hips, knees, ankles\n",
        "    if lefty:\n",
        "        hip_idx, knee_idx, ankle_idx = 11, 13, 15  # left leg\n",
        "    else:\n",
        "        hip_idx, knee_idx, ankle_idx = 12, 14, 16  # right leg\n",
        "\n",
        "    angle_sequence = []\n",
        "\n",
        "    for frame_num in range(prep_frame, release_frame + 1):\n",
        "        if frame_num not in frames_dict:\n",
        "            continue\n",
        "\n",
        "        keypoints = frames_dict[frame_num]['keypoints']\n",
        "\n",
        "        if any(idx >= len(keypoints) for idx in [hip_idx, knee_idx, ankle_idx]):\n",
        "            continue\n",
        "\n",
        "        angle = calculate_knee_angle(keypoints)  # assumes your function uses COCO convention internally\n",
        "        angle_sequence.append(angle)\n",
        "\n",
        "    return angle_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltiCfLfmOhuX"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def get_ball_center_from_bbox(bbox):\n",
        "    \"\"\"\n",
        "    Returns the center (x, y) of a bounding box.\n",
        "    Accepts either (x1, y1, x2, y2) or (x, y, w, h).\n",
        "    \"\"\"\n",
        "    if len(bbox) == 4:\n",
        "        if bbox[2] > bbox[0]:  # Assume (x1, y1, x2, y2)\n",
        "            x1, y1, x2, y2 = bbox\n",
        "            return ((x1 + x2) / 2, (y1 + y2) / 2)\n",
        "        else:  # Assume (x, y, w, h)\n",
        "            x, y, w, h = bbox\n",
        "            return (x + w / 2, y + h / 2)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid bbox format\")\n",
        "\n",
        "\n",
        "def calculate_ball_trajectory_on_release(frames_dict, release_frame, max_lookahead=5):\n",
        "    \"\"\"\n",
        "    Calculates the ball's upward trajectory angle at release using the release frame\n",
        "    and the next frame with a detected ball bounding box (within a given lookahead range).\n",
        "\n",
        "    Args:\n",
        "        frames_dict (dict): Dictionary of frame data with 'ball_bbox' entries.\n",
        "        release_frame (int): Frame index of the shot release.\n",
        "        max_lookahead (int): Maximum number of frames to look ahead for a valid detection.\n",
        "\n",
        "    Returns:\n",
        "        float or None: Upward trajectory angle in degrees, or None if insufficient data.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_ball_center_from_bbox(bbox):\n",
        "        if len(bbox) == 4:\n",
        "            if bbox[2] > bbox[0]:  # (x1, y1, x2, y2)\n",
        "                x1, y1, x2, y2 = bbox\n",
        "                return ((x1 + x2) / 2, (y1 + y2) / 2)\n",
        "            else:  # (x, y, w, h)\n",
        "                x, y, w, h = bbox\n",
        "                return (x + w / 2, y + h / 2)\n",
        "        return None\n",
        "\n",
        "    if release_frame not in frames_dict:\n",
        "        return None\n",
        "\n",
        "    ball_bbox_current = frames_dict[release_frame].get('ball_bbox')\n",
        "    if ball_bbox_current is None:\n",
        "        return None\n",
        "\n",
        "    center_current = get_ball_center_from_bbox(ball_bbox_current)\n",
        "\n",
        "    # Look forward for next frame with a valid ball detection\n",
        "    next_frame = None\n",
        "    center_next = None\n",
        "    for offset in range(1, max_lookahead + 1):\n",
        "        f = release_frame + offset\n",
        "        if f in frames_dict:\n",
        "            ball_bbox_next = frames_dict[f].get('ball_bbox')\n",
        "            if ball_bbox_next is not None:\n",
        "                center_next = get_ball_center_from_bbox(ball_bbox_next)\n",
        "                next_frame = f\n",
        "                break\n",
        "\n",
        "    if center_next is None:\n",
        "        return None  # No valid future detection found\n",
        "\n",
        "    dx = center_next[0] - center_current[0]\n",
        "    dy = center_current[1] - center_next[1]  # image space: upward is negative\n",
        "\n",
        "    angle_rad = math.atan2(dy, dx)\n",
        "    angle_deg = math.degrees(angle_rad)\n",
        "\n",
        "    return round(angle_deg, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EAg-A3ni9zC"
      },
      "outputs": [],
      "source": [
        "def generate_dtw_scores_and_angles(student_keypoints, teacher=\"SGA\", is_lefty=False):\n",
        "\n",
        "  keypoints_path = '/content/ComputingProject/TeacherSequences/'+teacher+'_keypoints.pkl'\n",
        "  with open(keypoints_path, 'rb') as f:\n",
        "    teacher_keypoint_data = pickle.load(f)\n",
        "\n",
        "  teacher_lefty = False\n",
        "\n",
        "  student_release_frame, student_release_angle = find_release_frame(student_keypoints)\n",
        "  student_load_frame, student_load_angle, student_knee_angle = find_load_frame(student_keypoints, student_release_frame, y_tolerance=5)\n",
        "  student_prep_frame = find_preparation_frame(student_keypoints, student_load_frame, lefty=is_lefty)\n",
        "\n",
        "  teacher_release_frame, teacher_release_angle = find_release_frame(teacher_keypoint_data)\n",
        "  teacher_load_frame, teacher_load_angle, teacher_knee_angle  = find_load_frame(teacher_keypoint_data, teacher_release_frame, y_tolerance=5)\n",
        "  teacher_prep_frame = find_preparation_frame(teacher_keypoint_data, teacher_load_frame, lefty=teacher_lefty)\n",
        "\n",
        "  student_elbows = generate_elbow_angle_sequence(student_keypoints, student_prep_frame, student_release_frame, lefty=is_lefty)\n",
        "  teacher_elbows = generate_elbow_angle_sequence(teacher_keypoint_data, teacher_prep_frame, teacher_release_frame, lefty=teacher_lefty)\n",
        "\n",
        "  student_knees = generate_knee_angle_sequence(student_keypoints, student_prep_frame, student_release_frame, lefty=is_lefty)\n",
        "  teacher_knees = generate_knee_angle_sequence(teacher_keypoint_data, teacher_prep_frame, teacher_release_frame, lefty=teacher_lefty)\n",
        "\n",
        "  elbow_score = compare_angle_sequences_dtw(student_elbows, teacher_elbows)\n",
        "  knee_score = compare_angle_sequences_dtw(student_knees, teacher_knees)\n",
        "\n",
        "  student_trajectory_angle = calculate_ball_trajectory_on_release(student_keypoints, student_release_frame)\n",
        "  teacher_trajectory_angle = calculate_ball_trajectory_on_release(teacher_keypoint_data, teacher_release_frame)\n",
        "\n",
        "\n",
        "  return elbow_score, knee_score, teacher_load_angle, teacher_knee_angle, teacher_release_angle, student_trajectory_angle, teacher_trajectory_angle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAVLszoUG8Mn"
      },
      "outputs": [],
      "source": [
        "analyse_video('/content/ComputingProject/inputVideos/FT_Train2.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A_FZNtlI4fH"
      },
      "outputs": [],
      "source": [
        "def visualise_shooter_with_ball_trajectory(frames_dict, video_path, output_path, release_frame=None):\n",
        "    \"\"\"\n",
        "    Creates visualisation with pose estimation and ball trajectory\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Could not open video {video_path}\")\n",
        "\n",
        "    # Get video properties directly from file (ensures compatibility)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Video writer with same parameters as track_shooter_full_video\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # Ball trajectory tracking\n",
        "    trajectory_points = []\n",
        "    release_y = None\n",
        "    ball_color = (0, 255, 0)  # BGR format (green)\n",
        "    trajectory_color = (255, 0, 0)  # BGR format (red)\n",
        "\n",
        "    # Get the first relevant frame from frames_dict\n",
        "    start_frame = min(frames_dict.keys())\n",
        "\n",
        "    # Sync the video\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "\n",
        "    for frame_num in sorted(frames_dict.keys()):\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_data = frames_dict[frame_num]\n",
        "\n",
        "        # 1. Create pose visualization\n",
        "        vis_frame = frame.copy()\n",
        "        if frame_data['keypoints'] is not None:\n",
        "            # Convert to MMPose format\n",
        "            vis_keypoints = np.array([frame_data['keypoints']])  # x,y only\n",
        "            vis_scores = np.array([frame_data['keypoint_scores']])\n",
        "\n",
        "            # Generate visualisation\n",
        "            metainfo = '/content/ComputingProject/mmpose/configs/_base_/datasets/coco.py'\n",
        "            combined_img = visualize(\n",
        "                cv2.cvtColor(vis_frame, cv2.COLOR_BGR2RGB),\n",
        "                vis_keypoints,\n",
        "                vis_scores,\n",
        "                metainfo=metainfo,\n",
        "                show=False\n",
        "            )\n",
        "\n",
        "            # Extract right half for keypoints visualisation (critical for dimensions)\n",
        "            height_temp, width_temp = combined_img.shape[:2]\n",
        "            vis_frame = combined_img[:, width_temp//2:]\n",
        "\n",
        "        # 2. Add ball trajectory (same as original tracking function)\n",
        "        if frame_data.get('ball_bbox'):\n",
        "            x1, y1, x2, y2 = frame_data['ball_bbox']\n",
        "            ball_center = (int((x1+x2)/2), int((y1+y2)/2))\n",
        "\n",
        "            # Initialise release height\n",
        "            if frame_num == release_frame:\n",
        "                release_y = ball_center[1]\n",
        "                release_y_padded = release_y + 100\n",
        "                trajectory_points = [ball_center]\n",
        "            elif release_y is not None and ball_center[1] <= release_y_padded:\n",
        "                trajectory_points.append(ball_center)\n",
        "\n",
        "            # Draw trajectory lines\n",
        "            for i in range(1, len(trajectory_points)):\n",
        "                cv2.line(vis_frame, trajectory_points[i-1], trajectory_points[i],\n",
        "                        trajectory_color, 2)\n",
        "\n",
        "            # Draw current ball position\n",
        "            cv2.circle(vis_frame, ball_center, 8, ball_color, -1)\n",
        "\n",
        "        # 3. Write frame (ensuring correct dimensions)\n",
        "        out.write(cv2.resize(vis_frame, (width, height)))\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGMQhZ1uYnBm"
      },
      "outputs": [],
      "source": [
        "def find_release_frame(frames_dict, max_ball_distance=80, top_n=5, lefty=False):\n",
        "    \"\"\"\n",
        "    iterative batch-wise release frame finder:\n",
        "    - Processes top-N wrist heights in batches\n",
        "    - For each frame: ball proximity first, fallback velocity check if no ball exists.\n",
        "    \"\"\"\n",
        "\n",
        "    import numpy as np\n",
        "    from scipy.signal import savgol_filter\n",
        "\n",
        "    if lefty:\n",
        "        shoulder_idx, elbow_idx, wrist_idx = 5, 7, 9\n",
        "    else:\n",
        "        shoulder_idx, elbow_idx, wrist_idx = 6, 8, 10\n",
        "\n",
        "    all_wrist_y = []\n",
        "    frame_nums = []\n",
        "    frame_data = {}\n",
        "\n",
        "    # Preprocess all frames\n",
        "    for frame_num, data in frames_dict.items():\n",
        "        keypoints = data.get('keypoints')\n",
        "        if keypoints is not None:\n",
        "            wrist_pos = keypoints[wrist_idx][:2]\n",
        "            all_wrist_y.append(wrist_pos[1])\n",
        "            frame_nums.append(frame_num)\n",
        "            frame_data[frame_num] = {\n",
        "                'wrist_y': wrist_pos[1],\n",
        "                'keypoints': keypoints,\n",
        "                'ball_bbox': data.get('ball_bbox')\n",
        "            }\n",
        "\n",
        "    # Smooth wrist positions\n",
        "    y_array = np.array(all_wrist_y)\n",
        "    smoothed_y = savgol_filter(y_array, 5, 2)\n",
        "\n",
        "    # Sort all frames by wrist height (lowest Y highest position)\n",
        "    sorted_indices = np.argsort(smoothed_y)\n",
        "    sorted_frames = [frame_nums[idx] for idx in sorted_indices]\n",
        "\n",
        "    # Iterate through sorted frames in batches of top_n\n",
        "    for batch_start in range(0, len(sorted_frames), top_n):\n",
        "        batch_frames = sorted_frames[batch_start: batch_start + top_n]\n",
        "\n",
        "        for candidate_frame in batch_frames:\n",
        "            candidate_data = frame_data[candidate_frame]\n",
        "            ball_bbox = candidate_data['ball_bbox']\n",
        "\n",
        "            # Ball proximity check first\n",
        "            if ball_bbox is not None:\n",
        "                x1, y1, x2, y2 = ball_bbox\n",
        "                ball_center = [(x1 + x2) / 2, (y1 + y2) / 2]\n",
        "                wrist_pos = candidate_data['keypoints'][wrist_idx][:2]\n",
        "                dist_to_ball = np.linalg.norm(wrist_pos - np.array(ball_center))\n",
        "\n",
        "                if dist_to_ball <= max_ball_distance:\n",
        "                    release_angle = calculate_elbow_angle(candidate_data['keypoints'], shoulder_idx, elbow_idx, wrist_idx)\n",
        "                    return candidate_frame, release_angle\n",
        "\n",
        "            # Fallback velocity check if no ball detection\n",
        "            elif ball_bbox is None:\n",
        "                idx_in_full = frame_nums.index(candidate_frame)\n",
        "                if idx_in_full < 3:\n",
        "                    continue\n",
        "\n",
        "                prior_y_vals = smoothed_y[idx_in_full - 3: idx_in_full + 1]\n",
        "                velocity = np.gradient(prior_y_vals)\n",
        "                avg_upward = -np.mean(velocity[:-1])\n",
        "\n",
        "                if avg_upward >= 3.0:  # threshold\n",
        "                    release_angle = calculate_elbow_angle(candidate_data['keypoints'], shoulder_idx, elbow_idx, wrist_idx)\n",
        "                    return candidate_frame, release_angle\n",
        "\n",
        "    # If all batches exhausted\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSkiMndGVLYC"
      },
      "outputs": [],
      "source": [
        "def crop_shooter(shooter_keypoints_data, frame_num, video_path, padding_ratio=0.3,target_size=256, paint_joints=[]):\n",
        "  \"\"\"\n",
        "  crops shooter for specified frame\n",
        "  \"\"\"\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "  cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
        "  ret, frame = cap.read()\n",
        "  frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  current_shooter_bbox = shooter_keypoints_data[frame_num]['bbox']\n",
        "  keypoints = shooter_keypoints_data[frame_num]['keypoints']\n",
        "  x1, y1, x2, y2 = current_shooter_bbox\n",
        "  w, h = x2 - x1, y2 - y1\n",
        "\n",
        "  # Calculate square crop with padding\n",
        "  size = max(w, h) * (1 + padding_ratio)\n",
        "  center_x, center_y = (x1 + x2)/2, (y1 + y2)/2\n",
        "\n",
        "  # Get crop coordinates\n",
        "  crop_x1 = max(0, int(center_x - size/2))\n",
        "  crop_y1 = max(0, int(center_y - size/2))\n",
        "  crop_x2 = min(frame.shape[1], int(center_x + size/2))\n",
        "  crop_y2 = min(frame.shape[0], int(center_y + size/2))\n",
        "\n",
        "\n",
        "\n",
        "  # Draw wrist marker on original frame (before cropping)\n",
        "  if paint_joints is not None:\n",
        "    for i in paint_joints:\n",
        "      joint_x, joint_y = keypoints[i][:2]\n",
        "      cv2.circle(frame_rgb, (int(joint_x), int(joint_y)), 5, (0, 255, 0), -1)  # Green dot\n",
        "\n",
        "\n",
        "  # Handle edge cases by adjusting opposite side\n",
        "  if crop_x1 < 0:\n",
        "      crop_x2 += abs(crop_x1)\n",
        "      crop_x1 = 0\n",
        "  if crop_y1 < 0:\n",
        "      crop_y2 += abs(crop_y1)\n",
        "      crop_y1 = 0\n",
        "  if crop_x2 > frame.shape[1]:\n",
        "      crop_x1 -= (crop_x2 - frame.shape[1])\n",
        "      crop_x2 = frame.shape[1]\n",
        "  if crop_y2 > frame.shape[0]:\n",
        "      crop_y1 -= (crop_y2 - frame.shape[0])\n",
        "      crop_y2 = frame.shape[0]\n",
        "\n",
        "  # Final crop and resize\n",
        "  crop = frame_rgb[crop_y1:crop_y2, crop_x1:crop_x2]\n",
        "  resized = cv2.resize(crop, (target_size, target_size))\n",
        "  return(resized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYMQjQhwh3mN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def compare_angle_sequences_dtw(seq1, seq2):\n",
        "    \"\"\"\n",
        "    Computes DTW distance between two sequences of joint angles.\n",
        "\n",
        "    Args:\n",
        "        seq1: List of angles (e.g., student)\n",
        "        seq2: List of angles (e.g., reference)\n",
        "\n",
        "    Returns:\n",
        "        float: DTW distance score (lower = more similar)\n",
        "    \"\"\"\n",
        "    # Convert to 2D arrays for DTW (shape: (n, 1))\n",
        "    seq1 = np.array(seq1).reshape(-1, 1)\n",
        "    seq2 = np.array(seq2).reshape(-1, 1)\n",
        "\n",
        "    distance, _, _, path = dtw(seq1, seq2, dist=lambda x, y: np.abs(x - y))\n",
        "    normalised_score = (distance / len(path[0]))\n",
        "    return normalised_score\n",
        "\n",
        "def interpret_dtw_score(score):\n",
        "  if score < 5:\n",
        "      return \"Excellent ‚Äì movement closely matches the reference.\"\n",
        "  elif score < 10:\n",
        "      return \"Good ‚Äì minor inconsistencies in form.\"\n",
        "  elif score < 20:\n",
        "      return \"Moderate ‚Äì noticeable form variations.\"\n",
        "  else:\n",
        "      return \"Needs Improvement ‚Äì substantial deviation from reference technique.\"\n",
        "\n",
        "def generate_joint_recommendations(student_angle, teacher_angle, joint_name):\n",
        "    diff = student_angle - teacher_angle\n",
        "    if abs(diff) < 5:\n",
        "        return f\"Your {joint_name} angle is well aligned with the reference.\"\n",
        "    elif diff > 0:\n",
        "        return f\"Try reducing your {joint_name} angle slightly during the shot for a more compact form.\"\n",
        "    else:\n",
        "        return f\"Consider increasing your {joint_name} angle to better mirror the reference motion.\"\n",
        "\n",
        "def generate_trajectory_recommendation(student_angle, teacher_angle):\n",
        "    if student_angle is None or teacher_angle is None:\n",
        "        return \"No trajectory data available for comparison.\"\n",
        "    diff = student_angle - teacher_angle\n",
        "    if abs(diff) < 3:\n",
        "        return \"‚úÖ Your shot arc closely matches the reference ‚Äî well done!\"\n",
        "    elif diff > 0:\n",
        "        return \"‚¨ÜÔ∏è Your shot arc is higher than the reference. This may improve forgiveness, but watch for loss of power or overcompensation.\"\n",
        "    else:\n",
        "        return \"‚¨áÔ∏è Your shot arc is flatter than the reference. Consider increasing your upward wrist motion for a softer, more controlled release.\"\n",
        "\n",
        "\n",
        "def build_recommendation_section(elbow_score, knee_score, student_angles, teacher_angles):\n",
        "    load_elbow_student, load_knee_student, release_elbow_student, trajectory_s = student_angles\n",
        "    load_elbow_teacher, load_knee_teacher, release_elbow_teacher, trajectory_t = teacher_angles\n",
        "\n",
        "    elbow_band = interpret_dtw_score(elbow_score)\n",
        "    knee_band = interpret_dtw_score(knee_score)\n",
        "\n",
        "    elbow_tip = generate_joint_recommendations(load_elbow_student, load_elbow_teacher, \"elbow (load phase)\")\n",
        "    knee_tip = generate_joint_recommendations(load_knee_student, load_knee_teacher, \"knee (load phase)\")\n",
        "    release_tip = generate_joint_recommendations(release_elbow_student, release_elbow_teacher, \"elbow (release phase)\")\n",
        "    traj_tip = generate_trajectory_recommendation(trajectory_s, trajectory_t)\n",
        "\n",
        "    if trajectory_s is None:\n",
        "      trajectory_s = \"N/A\"\n",
        "    else:\n",
        "      trajectory_s = f\"{trajectory_s:.1f}\"\n",
        "\n",
        "\n",
        "    return (\n",
        "        f\"### üîç Recommendations\\n\"\n",
        "        f\"**Elbow Form (DTW Score: {elbow_score:.2f})** ‚Äî {elbow_band}\\n\"\n",
        "        f\"{elbow_tip}\\n\"\n",
        "        f\"{release_tip}\\n\\n\"\n",
        "        f\"**Knee Form (DTW Score: {knee_score:.2f})** ‚Äî {knee_band}\\n\"\n",
        "        f\"{knee_tip}\\n\\n\"\n",
        "        f\"**Ball Trajectory**\\n\"\n",
        "        f\"Student: {trajectory_s:}¬∞ | Reference: {trajectory_t:.1f}¬∞\\n\"\n",
        "        f\"{traj_tip}\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by8i2mxcHN-D"
      },
      "outputs": [],
      "source": [
        "\n",
        "def analyse_video(video_path, is_lefty=False, chosen_teacher=\"SGA\"):\n",
        "\n",
        "  # progess message yield\n",
        "  yield None, None, None, \"\", \"\", \"üîÑ Initialising models...\"\n",
        "  # Initialise models\n",
        "  yolo_model = YOLO('/content/ComputingProject/yolov11/best.pt')\n",
        "\n",
        "  mmpose_inferencer_2d = MMPoseInferencer('human')\n",
        "\n",
        "  weights_3d = '/content/ComputingProject/mmpose/checkpoints/videopose_h36m_1frame_fullconv_supervised_cpn_ft-5c3afaed_20210527.pth'\n",
        "  config_3d = '/content/ComputingProject/mmpose/configs/body_3d_keypoint/video_pose_lift/h36m/video-pose-lift_tcn-1frm-supv-cpn-ft_8xb128-160e_h36m.py'\n",
        "  mmpose_inferencer_3d = MMPoseInferencer(\n",
        "  pose3d=config_3d,\n",
        "  pose3d_weights=weights_3d,\n",
        "  device='cuda:0'\n",
        "  )\n",
        "\n",
        "  if isinstance(video_path, str):\n",
        "        # Regular file path (testing)\n",
        "        input_path = video_path\n",
        "        # Create temp output file\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as output_tmp:\n",
        "            output_path = output_tmp.name\n",
        "  else:\n",
        "        # Gradio file object (deployment)\n",
        "        with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as input_tmp, \\\n",
        "            tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as output_tmp:\n",
        "\n",
        "            # Save uploaded video\n",
        "            with open(input_tmp.name, \"wb\") as f:\n",
        "                f.write(video_path.read())\n",
        "            input_path = input_tmp.name\n",
        "            output_path = output_tmp.name\n",
        "\n",
        "\n",
        "  yield None, None, None, \"\", \"\", \"üìπ Tracking shooter and extracting keypoints...\"\n",
        "  # start video processing\n",
        "  is_lefty = (hand_radio == \"Left-handed\")\n",
        "  keypoints_data = track_shooter_full_video(input_path, yolo_model, mmpose_inferencer_2d)\n",
        "\n",
        "  yield None, None, None, \"\", \"\", \"üìå Identifying shot phases...\"\n",
        "\n",
        "  release_frame, release_angle = find_release_frame(keypoints_data, lefty=is_lefty)\n",
        "  load_frame, load_angle, knee_angle=find_load_frame(keypoints_data, release_frame, lefty=is_lefty)\n",
        "\n",
        "  # Generate outputs visualisations\n",
        "  yield None, None, None, \"\", \"\", \"üéØ Visualising 2D output...\"\n",
        "\n",
        "  visualise_shooter_with_ball_trajectory(\n",
        "      frames_dict=keypoints_data,\n",
        "      video_path=input_path,\n",
        "      output_path=output_path,\n",
        "      release_frame=release_frame,\n",
        "  )\n",
        "\n",
        "  yield None, None, None, \"\", \"\", \"ü¶æ Running 3D lifting...\"\n",
        "  # Cropping Key Phases for 3d lifting\n",
        "  release_crop = crop_shooter(keypoints_data, release_frame, input_path)\n",
        "  load_crop = crop_shooter(keypoints_data, load_frame, input_path)\n",
        "\n",
        "  # 3D lifting\n",
        "  release_dict = next(mmpose_inferencer_3d(release_crop, return_vis=True, num_instances = 1))\n",
        "  load_dict = next(mmpose_inferencer_3d(load_crop, return_vis=True, num_instances = 1))\n",
        "\n",
        "  release_vis = cv2.cvtColor(release_dict['visualization'][0], cv2.COLOR_BGR2RGB)\n",
        "  load_vis = cv2.cvtColor(load_dict['visualization'][0], cv2.COLOR_BGR2RGB)\n",
        "  release_vis = Image.fromarray(release_vis)\n",
        "  load_vis = Image.fromarray(load_vis)\n",
        "\n",
        "  yield None, None, None, \"\", \"\", \"üìä Calculating DTW scores...\"\n",
        "\n",
        "  # dtw score calculation\n",
        "  elbow_score, knee_score, teacher_load_angle, teacher_knee_angle, teacher_release_angle, student_trajectory_angle, \\\n",
        "   teacher_trajectory_angle = generate_dtw_scores_and_angles(keypoints_data, is_lefty=is_lefty, teacher=chosen_teacher)\n",
        "\n",
        "  recommendation_section = build_recommendation_section(\n",
        "  elbow_score, knee_score,\n",
        "  student_angles=(load_angle, knee_angle, release_angle, student_trajectory_angle),\n",
        "  teacher_angles=(teacher_load_angle, teacher_knee_angle, teacher_release_angle, teacher_trajectory_angle))\n",
        "\n",
        "  if student_trajectory_angle is None:\n",
        "      student_trajectory_angle = \"N/A\"\n",
        "  else:\n",
        "      student_trajectory_angle = f\"{student_trajectory_angle:.1f}\"\n",
        "\n",
        "\n",
        "\n",
        "  summary = (\n",
        "    f\"### üìä DTW Similarity Scores\\n\"\n",
        "    f\"- Elbow: {elbow_score:.2f}\\n\"\n",
        "    f\"- Knee: {knee_score:.2f}\\n\\n\"\n",
        "    f\"### üßç‚Äç‚ôÇÔ∏è Joint Angles (Student vs {chosen_teacher})\\n\"\n",
        "    f\"**Load Phase:**\\n\"\n",
        "    f\"- Elbow: {load_angle:.1f}¬∞ / {teacher_load_angle:.1f}¬∞\\n\"\n",
        "    f\"- Knee: {knee_angle:.1f}¬∞ / {teacher_knee_angle:.1f}¬∞\\n\"\n",
        "    f\"**Release Phase:**\\n\"\n",
        "    f\"- Elbow: {release_angle:.1f}¬∞ / {teacher_release_angle:.1f}¬∞\\n\\n\"\n",
        "    f\"### üèÄ Ball Trajectory at Release\\n\"\n",
        "    f\"- Student: {student_trajectory_angle}¬∞\\n\"\n",
        "    f\"- {chosen_teacher}: {teacher_trajectory_angle:.1f}¬∞\\n\"\n",
        "  )\n",
        "\n",
        "\n",
        "  yield output_path, release_vis, load_vis, summary, recommendation_section, \"‚úÖ Analysis complete!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6-G_C0KsClIN"
      },
      "outputs": [],
      "source": [
        "### GUI INITIALISATION ###\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"## üèÄ Basketball Shot Analyser\")\n",
        "\n",
        "    # Progress bar at the top\n",
        "    progress_text = gr.Textbox(\n",
        "        label=\"Progress\",\n",
        "        lines=2,\n",
        "        max_lines=2,\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # upload video and other input args\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            video_input = gr.Video(label=\"Upload Shot Video\", height=320)\n",
        "        with gr.Column(scale=1):\n",
        "            hand_radio = gr.Radio(\n",
        "                [\"Right-handed\", \"Left-handed\"],\n",
        "                label=\"Shooter's Dominant Hand\",\n",
        "                value=\"Right-handed\"\n",
        "            )\n",
        "            teacher_dropdown = gr.Dropdown(\n",
        "                [\"SGA\", \"Vanfleet\"],\n",
        "                label=\"Select Reference Player (Teacher)\",\n",
        "                value=\"SGA\"\n",
        "            )\n",
        "            submit_btn = gr.Button(\"Analyse Shot\", variant=\"primary\")\n",
        "\n",
        "    # 3d poses and 2d vis\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=2):\n",
        "            video_output = gr.Video(label=\"Processed Video with Ball Trajectory\", height=320)\n",
        "        with gr.Column(scale=1):\n",
        "            with gr.Row():\n",
        "                release_img = gr.Image(label=\"3D Pose: Release Frame\", type=\"pil\", height=150)\n",
        "            with gr.Row():\n",
        "                load_img = gr.Image(label=\"3D Pose: Load Frame\", type=\"pil\", height=150)\n",
        "\n",
        "    # analysis and recommendation text boxes\n",
        "    with gr.Row():\n",
        "      with gr.Column(scale=1):\n",
        "          analysis_summary = gr.Textbox(\n",
        "              label=\"üìä Analysis Summary\",\n",
        "              lines=10,\n",
        "              max_lines=20,\n",
        "              interactive=False,\n",
        "              show_copy_button=True\n",
        "          )\n",
        "      with gr.Column(scale=1):\n",
        "          recommendation_summary = gr.Textbox(\n",
        "              label=\"üîç Recommendations\",\n",
        "              lines=10,\n",
        "              max_lines=20,\n",
        "              interactive=False,\n",
        "              show_copy_button=True\n",
        "          )\n",
        "\n",
        "    # Button wiring ‚Äî `analyse_video` yields results directly\n",
        "    submit_btn.click(\n",
        "        fn=analyse_video,\n",
        "        inputs=[video_input, hand_radio, teacher_dropdown],\n",
        "        outputs=[video_output, release_img, load_img, analysis_summary, recommendation_summary, progress_text]\n",
        "    )\n",
        "\n",
        "app.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
